<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LSD COW DETECTION WITH YOLOV11n</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
</head>

<body class="bg-gray-100 font-sans">
    <div class="container mx-auto px-4 py-8">
        <h1 class="text-3xl font-semibold text-center text-gray-800 mb-6">LSD COW DETECTION WITH YOLOV11n</h1>
        <div id="alert" class="text-center text-sm bg-gray-200 text-gray-700 px-4 py-2 rounded-lg shadow mb-6">
            Wait for Model Initialization...
        </div>
        <div class="flex flex-col items-center">
            <!-- Video Section -->
            <div class="w-full max-w-md mb-6">
                <div class="aspect-w-4 aspect-h-3 bg-gray-300 rounded-lg overflow-hidden shadow-lg">
                    <video id="video" class="w-full h-full object-cover" autoplay></video>
                </div>
            </div>

            <!-- Canvas Section -->
            <div class="w-full max-w-md mb-6">
                <div class="aspect-w-4 aspect-h-3 bg-gray-300 rounded-lg overflow-hidden shadow-lg">
                    <canvas id="canvas" class="w-full h-full object-cover"></canvas>
                </div>
            </div>

            <!-- Buttons -->
            <div class="space-x-3">
                <button id="cameraSwitch"
                    class="px-6 py-2 bg-blue-600 text-white text-sm font-medium rounded-lg shadow hover:bg-blue-500 focus:outline-none focus:ring-2 focus:ring-blue-300">
                    Switch Camera
                </button>
                <button id="model1"
                    class="px-6 py-2 bg-gray-200 text-gray-700 text-sm font-medium rounded-lg shadow hover:bg-gray-300 focus:outline-none focus:ring-2 focus:ring-gray-400">
                    Far Away Check
                </button>
                <button id="model2"
                    class="px-6 py-2 bg-gray-200 text-gray-700 text-sm font-medium rounded-lg shadow hover:bg-gray-300 focus:outline-none focus:ring-2 focus:ring-gray-400">
                    Close Up Check
                </button>


            </div>
                        <!-- Upload Video Button -->
                        <div class="w-full max-w-md">
                            <input type="file" id="uploadVideo" accept="video/*" class="mb-3">
                            <button id="processVideo"
                                class="px-6 py-2 bg-green-600 text-white text-sm font-medium rounded-lg shadow hover:bg-green-500 focus:outline-none focus:ring-2 focus:ring-green-300">
                                Upload and Detect Video
                            </button>
                        </div>
        </div>
    </div>

    <footer class="text-center text-sm text-gray-500 mt-8">
        Real-Time YOLO Detection &copy; 2025
    </footer>

    <script>
        const socket = io.connect('https://lsddetectionukdc.duckdns.org/');

        // Access webcam stream
        const videoElement = document.getElementById('video');
        const canvasElement = document.getElementById('canvas');
        const context = canvasElement.getContext('2d');
        let currentStream = null;
        let facingMode = 'environment';
        let constraints = { video: { width: 640, height: 480, facingMode: facingMode } };

        // Access webcam stream function
        function startVideoStream(constraints) {
            navigator.mediaDevices.getUserMedia(constraints)
                .then(function (stream) {
                    if (currentStream) {
                        currentStream.getTracks().forEach(track => track.stop());
                    }
                    videoElement.srcObject = stream;
                    currentStream = stream;

                    // Adjust canvas size after video stream starts
                    videoElement.onloadedmetadata = function () {
                        canvasElement.width = videoElement.videoWidth;
                        canvasElement.height = videoElement.videoHeight;
                    };
                })
                .catch(function (err) {
                    console.error('Error accessing webcam:', err);
                });
        }

        // Initialize with the front camera
        startVideoStream(constraints);
        // Toggle between front and back camera
        document.getElementById('cameraSwitch').addEventListener('click', function () {
            // Ubah facingMode antara kamera depan dan belakang
            facingMode = facingMode === 'user' ? 'environment' : 'user'; // Switch between 'user' and 'environment'

            // Update constraints dengan facingMode baru
            constraints = { video: { width: 640, height: 480, facingMode: facingMode } };

            // Hentikan stream lama sebelum memulai yang baru
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }

            // Mulai video stream dengan constraints yang baru
            startVideoStream(constraints);
        });

        // Capture frames and send to the server
        videoElement.addEventListener('play', function () {
            let frameCount = 0;
            const framesToSkip = 100; // Send one frame every 100 frames (reduce this number further if needed)

            function draw() {
                if (videoElement.paused || videoElement.ended) return;

                // Skip frames by checking frame count
                if (frameCount % framesToSkip === 0) {
                    const canvas = document.createElement('canvas');
                    canvas.width = videoElement.videoWidth;
                    canvas.height = videoElement.videoHeight;
                    const context = canvas.getContext('2d');

                    // Draw the video frame onto the temporary canvas
                    context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

                    // Convert the frame to a base64 image and emit it through the socket
                    const base64Image = canvas.toDataURL('image/png');
                    socket.emit('stream', { image: base64Image.split(',')[1] });
                }

                frameCount++;
                // Continue drawing next frame
                requestAnimationFrame(draw);
            }

            // Start the drawing loop
            draw();
        });

        // Receive processed image from the server and display it
        socket.on('image', function (data) {
            const img = new Image();
            img.onload = function () {
                // Clear the canvas before drawing the new image
                context.clearRect(0, 0, canvasElement.width, canvasElement.height);

                // Draw the received image onto the canvas
                context.drawImage(img, 0, 0);

                // Draw bounding boxes after the image is loaded and drawn
                if (data.boxes && data.boxes.length > 0) {
                    data.boxes.forEach(function (box) {
                        context.beginPath();
                        context.rect(box.x1, box.y1, box.x2 - box.x1, box.y2 - box.y1);
                        context.lineWidth = 2;
                        context.strokeStyle = 'red';
                        context.fillStyle = 'red';
                        context.stroke();
                        context.fillText(box.label, box.x1, box.y1 - 10);
                    });
                }
            };
            img.src = 'data:image/png;base64,' + data.image;
        });

        // Handle model switching
        document.getElementById('model1').addEventListener('click', function () {
            socket.emit('change_model', { model_path: 'yolov11n_modelLumpySkinwith2class_old.pt' });
            showAlert('Switched to Model 1: Far Away Check', 1000000);
        });

        document.getElementById('model2').addEventListener('click', function () {
            socket.emit('change_model', { model_path: 'yolov11n_modelLumpySkinwith2classdeeper.pt' });
            showAlert('Switched to Model 2: Close Up Check', 1000000);
        });

        socket.on('model_changed', function (data) {
            if (data.success) {
                alert(`Model successfully switched to: ${data.model}`);
            } else {
                alert(`Error switching model: ${data.error}`);
            }
        });

        function showAlert() {
            const alertBox = document.getElementById('alert');

            // Show alert
            alertBox.style.display = 'block';

            // Hide alert after 15 seconds
            setTimeout(() => {
                alertBox.style.display = 'none';

                // Wait for 1 minute before re-initializing
                console.log("Waiting for 1 minute...");
                setTimeout(() => {
                    console.log("Initialization complete.");
                }, 60000); // 1 minute = 60000ms
            }, 30000); // 15 seconds = 15000ms
        }
        showAlert();

                // Handle video upload and processing
            document.getElementById('processVideo').addEventListener('click', function () {
            const fileInput = document.getElementById('uploadVideo');
            if (!fileInput.files.length) {
                alert('Please select a video file to upload.');
                return;
            }

            const file = fileInput.files[0];
            const reader = new FileReader();

            reader.onload = function () {
                socket.emit('process_video', { video: reader.result });
            };

            reader.readAsDataURL(file);
        });

        socket.on('processed_video', function (data) {
            const a = document.createElement('a');
            a.href = 'data:video/mp4;base64,' + data.video;
            a.download = 'processed_video.mp4';
            a.click();
        });
    </script>
</body>

</html>
